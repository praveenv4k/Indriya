% Chapter Template

\chapter{Conclusion} % Main chapter title
\label{Chapter7} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
\lhead{Chapter 7. \emph{Conclusion}} 
\section{Project Summary}
In this section summary of the Indriya platform is described
\subsection{System specification}
 The Indriya platform could be seen as a product by itself. The product specification is shown in Table~\ref{table:system_spec}.

\begin{table}[H]
\centering
%\small
\caption{Indriya specification}
\label{table:system_spec}
\begin{tabular}{| p{3.1cm} | p{12cm} |}
\hline
  Hardware & \begin{itemize}[leftmargin=*,topsep={0pt},itemsep={0pt},partopsep={0pt},parsep={0pt}] 
                                                  \item Supported Robots: Nao
                                                  \item Sensor: Kinect for Windows V2
                                                  \item PC: x64 processor, min 4GB memory, Physical dual-core 3.1 GHz or more, USB 3.0 controller, DX11 capable graphics adapter
                                                  \end{itemize} 
                                          \tabularnewline\hline
                                          
  Software &  \begin{itemize}[leftmargin=*,topsep={0pt},itemsep={0pt},partopsep={0pt},parsep={0pt}] 
                                                  \item Platform: Windows 8.1
                                                  \item For running: Microsoft .NET 4.5.1, Visual C++ 2013 redistributable, Naoqi Python SDK v2.3.3, Kinect for Windows SDK
                                                  \item For developing: Please go through readme file: \url{https://github.com/praveenv4k/Indriya/blob/master/README.md}
                                                \end{itemize} 
                                          \tabularnewline\hline
\end{tabular}
\end{table}

In summary Indriya platform
\begin{itemize}
\item Is a software to design HRI scenarios based on human behaviors
\item Gives opportunity to augment multimodal sensor to the existing perception system of the robot
\item Provides easy to user interface for designing the scenarios
\end{itemize}
and it is not
\begin{itemize}
\item A system to design low level control of a robot
\end{itemize}
	
The source code of the complete platform is available as Open source at \url{https://github.com/praveenv4k/Indriya}. 
\subsection{Project Statistics}
The project has an extensive code base consisting of over 30k lines of code (counted using CLOC tool). The software has been written using diverse programming language according to the best fit for the purpose. The code statistics is shown in Fig.\ref{fig:code_stats}.
% \begin{table}[h!]
%   \begin{center}
%     \caption{Project Code Statistics}
%     \label{table:code_stats}
%     \pgfplotstabletypeset[
%       columns = {language,comment,code},
%       multicolumn names, % allows to have multicolumn names
%       col sep=comma, % the seperator in our .csv file
%       %display columns/0/.style={
%       %    column name=$Files$, % name of first column
%       %    column type={S},string type
%       %},  % use siunitx for formatting
%       %display columns/0/.style={
%       %    column name=$Files$,
%       %    string type
%       %},  % use siunitx for formatting
%       display columns/0/.style={
%         column name=$Language$,
%         string type
%       },
%       %display columns/1/.style={
%       %  column name=$Blank$,
%       %  string type
%       %},
%       display columns/1/.style={
%         column name=$Comment$,
%         string type
%       },
%       display columns/2/.style={
%         column name=$Code$,
%         string type
%       },
%       every head row/.style={
%         before row={\toprule}, % have a rule at top
%         after row={
%           %\si{\ampere} & \si{\volt}\\ % the units seperated by &
%           \midrule} % rule under units
%       },
%       every last row/.style={after row=\bottomrule}, % rule at bottom
%     ]{assets/cloc_code_statistics.csv} % filename/path to file
%   \end{center}
% \end{table}

% \begin{figure}[H]
% \centering
% \begin{tikzpicture} 
% \pie[text=legend]{43.85/C\#, 22.83/C++, 9.52/Python, 6.96/Javascript, 16.8/Others} 
% \end{tikzpicture}
% \caption[NAO museum guide: Experiment setup]{NAO museum guide: Experiment setup}
% \label{fig:pie}
% \end{figure}
\begin{figure}[!ht]
  %\centering
  %\rule{6.4cm}{3.6cm}
  \begin{tikzpicture}[scale=0.8]
  %\pie[text=legend]{43.85/C\#, 22.83/C++, 9.52/Python, 6.96/Javascript, 16.8/Others} 
  %\pie[ cloud , text = inside , scale font ]{43.85/C\#, 22.83/C++, 9.52/Python, 6.96/Javascript, 16.8/Others}
  \pie[ cloud , text = inside ]{43.85/C\#, 22.83/C++, 9.52/Python, 6.96/JS, 16.8/Others}
  %\pie[ square]{43.85/C\#, 22.83/C++, 9.52/Python, 6.96/JS, 16.8/Others}
  \end{tikzpicture}
  \qquad
  \begin{tabular}[b]{cc}\hline
    Language & Lines of code \\ \hline
    C\# & 0 \\
    C++ & 0 \\
    Python & 0 \\
    Javascript (JS) & 0 \\
    Others & 0 \\
    Total & 0 \\ \hline
  \end{tabular}
  %\captionlistentry[table]{Indriya: Code statistics}
  %\captionsetup{labelformat=andtable}
  \caption{Indriya: Code statistics}
    \label{fig:code_stats}
\end{figure}

\subsection{Scope for prospective work}
  The Indriya platform has tremendous scope for future developments. Some of the directions that could be thought are

\begin{itemize}
\item Developing a huge database of commonly encountered gestures in social environment
\item Developing an extensive database of robot actions that the user expects it do on a daily basis
\item Developing an interface definition language to generate the visual programming blocks and code generation modules for those blocks automatically.
\item Integration of data management system/user databases to persist and retrieve user information for personalized interaction experience
\item Integration of sensors available in smartphone and wearable devices like IMUs, Gyroscopes, GPS etc.,
\item Integration of Natural Language Processing systems with the speech recognition module for more natural interaction
\item Increasing the range of operation of Humanoid robots by fusing data from two or more Kinect sensors 
\item Support for social behavior learning and intelligence modules for dynamic adoption of human like behavior by robots
\end{itemize}

\section{Conclusion} % Main chapter title
Human Robot Interaction is a complex interdisciplinary problem that needs expertise in various fields like human computer interaction, psychology, sociology, humanoid robotics etc., Social robots have become very common in the recent days and they find useful applications in entertainment, education, autism treatment and elderly care. 

For an efficient interaction with human, the robot has to understand his/her behaviors and also the environment around him. This is only possible when the robot has necessary perception capabilities to make it aware of the situation. However the onboard sensors most often cannot deliver all the information necessary for an effective interaction. The abundance of smart devices and sensors in the smart home and public environments can be exploited for this purpose and RGB-D sensors like Microsoft Kinect provides a convincing solution.

The people from interdisciplinary fields wanting to develop a rich interaction scenario find it difficult to use the existing technology as it requires strong background in programming. Any new programming paradigm designed for such purposes should find a correct balance between simplicity and expressiveness which was the main motivation behind this thesis. The behavior programming paradigm proposed in this thesis could be used for studying various aspects of HRI such as efficiency of the system, cooperativeness, social acceptance etc., There exist some open questions and challenges to be addressed however. The preliminary challenges are to find a set of all possible human motions that could be understood from the sensors distributed around in the environment and to identify all possible actions a robot could perform to interact with human in a social interaction scenario. The next question is to find the spectrum of interaction scenarios this kind of programming interface could cover. 