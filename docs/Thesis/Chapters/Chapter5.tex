% Chapter Template

\chapter{System capabilities evaluation} % Main chapter title

\label{Chapter5} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 5. \emph{System capabilities evaluation}} 

In this chapter various capabilities of Indriya system have been evaluated. The evaluation has been done from a platform developer point of view. The features discussed ranges from intuitiveness to designing complex parallel behaviors on multiple robots. We describe how Indriya system could be used for realistic cases using example programs which would be otherwise extremely difficult to realize using existing methods for a novice programmer.
\section{Indriya: Sensible, intuitive and first of its kind}
In order to describe the simplicity and intuitiveness, we will make a comparative study of a scenario designed with Indriya and with that of Choregraphe behavior design software that comes with NAO humanoid robot. 
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../thesis/assets/scenario_museum.png}
\caption[NAO museum guide: Experiment setup]{NAO museum guide: Experiment setup}
\label{fig:scenario1_setup}
\end{figure}
\subparagraph{Scenario:}The NAO humanoid robot is a guide in a museum. The museum manager would like to design a scenario where when a visitor comes into the vicinity of the robot, the robot would approach him/her and start explaining the history of the museum. The experiment setup for this scenario is shown in Fig~\ref{fig:scenario1_setup}. We would like to use this scenario to compare the expressiveness and intuitiveness of behavior description with Choregraphe \cite{NaoRobot} shown in Fig~\ref{fig:scenario1_program_choregraphe} and with our interface shown in Fig~\ref{fig:scenario1_program}.
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{../thesis/assets/scenario_museum_choregraphe2.png}
\caption[NAO museum guide: Choregraphe program]{NAO museum guide: Choregraphe program}
\label{fig:scenario1_program_choregraphe}
\end{figure}
The behavior program desgined using Choregraphe software is shown in Fig.~\ref{fig:scenario1_program_choregraphe}. Though Choregraphe uses a familiar flow-chart based programming model and has a huge library of primitive blocks to build complex motion patterns, the data flow for this scenario is not straight forward. As could be noticed from Fig~\ref{fig:scenario1_program_choregraphe}, at first the robot keeps looking for people in its vicinity using the \emph{Face detection block} at the cost of its power. The battery may be used up even before the robot really detects a person. Once it detects a person, the face detection block is stopped and \emph{People tracker} block is activated. The robot starts approaching (tracking) the person until a fixed distance with the person is reached. Once the desired distance of separation is achieved, the people tracker block is stopped. Now the robot will actually start explaining the history of the museum. It could be noticed that this kind of description/design of scenario might be easy for a seasoned programmer. However for a novice programmer it could be difficult to think of the dataflow as they literally have to emulate the whole scenario in their mind before designing the system. Moreover for human-in-the-loop scenarios like this, it is extremely difficult to simulate the behavior. So each time in order to verify the behavior, it has to be executed in the real robot which increases the overhead of the design process.

Now let us see how such a scenario could be designed using Indriya system. The definition of this scenario is straightforward using Indirya as shown in Fig~\ref{fig:scenario1_program}.
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{../thesis/assets/scenario1_new.png}
\caption[NAO museum guide: Indriya program]{NAO museum guide: Indriya program}
\label{fig:scenario1_program}
\end{figure}
The framework equipped with Kinect sensor takes care of the detection of people and gives the relative localization of the robot and human. Once the person is detected or a configured gesture trigger arrives, the behavior program retrieves the dynamic position of the robot and of the human from the application context. Using this information, the relative transformation of the human with respect to human is computed. The \emph{Approach block} makes use of this information to drive the robot towards the person. After coming into the proximity of the person, the robot starts explaining the history of museum configured using \emph{Say Expressively} block. From the user perspective, the design of the behavior is \textbf{\emph{intuitive}} using Indriya. He/She can focus on the scenario rather than thinking about the minute details of the data flow as the Indriya system equipped with the perception system acts as a proxy and eases the design process. 

The fact that there exists no system as of this writing which could bridge the multimodal system and social robots and on top of this enables novice programmers to design \emph{sensible} scenarios which makes Indriya \emph{unique} and \emph{first of its kind}.

\section{Realistic scenario design}
The Indriya system is not just for toy problems. In this section let us see how it could be used for realistic therapy scenario which is increasingly becoming important for rehabilitation. 
\subparagraph{Scenario:}A physiotherapist who is in a remote hospital would like to prepare an exercise routine for his patient who is recovering from the fracture of his left hand. The therapist wants the service robot in the rehabilitation center to give directions to the patient in an interactive manner and facilitate the process. The exercise is composed of: an introduction and demonstration of the routine, interactively reporting the progress of the exercise and finally notifying the completion. The experiment setup is shown in Fig.~\ref{fig:scenario2_setup}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{../thesis/assets/scenario_therapy.png}
\caption[NAO therapy facilitator: Experiment setup]{NAO therapy facilitator: Experiment setup}
\label{fig:scenario2_setup}
\end{figure}
Though Choregraphe software gives the capability of programming behaviors with basic human awareness, it does not explicitly allows programming that takes into account human gestures/motions. This is not the drawback of the system but the fact that it does not enough sensors to understand complex motions. Thanks to the Kinect sensor and its gesture recognition capabilites, one can exploit it to design a program for the above scenario using Indriya system. A reference implementation of such a scenario using our behavior interface is shown in Fig~\ref{fig:scenario2_program}.
\begin{figure}
\centering
\includegraphics[width=\textwidth]{../thesis/assets/scenario2_new.png}
\caption[NAO therapy facilitator: Indriya program]{NAO therapy facilitator: Indriya program}
\label{fig:scenario2_program}
\end{figure}
The above program is designed using all the three basic behavior constructs that constitutes the behavior program. In the Startup behavior the robot gives an introduction about the exercise routine and then gives a demonstration of how to do it. A trigger behavior block is configured to be triggered each time when the patient performs the therapy routine (lifting left hand). Inside the trigger behavior block in its startup block a variable is initialized to keep track of the count of the triggers. In the cyclic block, the variable is incremented and then the robot notifies the progress of the exercise by announcing how many times the patient has completed the exercise. The trigger behavior block is configured \emph{Until} a desired condition on the exercise count is reached (say lifting left hand 5 times). Once the lifetime of the trigger behavior block expires, the robot gives some closing comments about the routine. It could be noticed that the description of this scenario is quite simple using the Indriya. The blockly editor powered with the behavior program logic abstracts the complexity of designing realistic scenarios.

\section{Priority execution making real sense}
Most often in real life HRI scenarios one would like to have robot respond to certain events with a higher priority irrespective of what it is doing at that time. Priority based execution capability comes handy in such scenarios. Priority based execution is inspired from computer processor architectures and scheduling of processes. The inherent problem is that often these concepts are extremely difficult to understand/implement for beginner to intermediate level programmers. The Indriya system makes this extremely easy by just fixing the priority of each behavior blocks. This capability is elucidated in the scenario described below. 

\subparagraph{Scenario:}Let us consider an elderly care robot who takes care of a fictitious person Mr. Adams. The living room is equipped with kinect sensor so that the activities and voice commands of the person could be recognized by Indriya system. The care taker of Mr. Adams who is working during the day would like to design a behavior program for the robot. He/She wants the robot to respond to normal commands like \emph{Come here}, \emph{Bring Coffee} etc., Among others he would like the robot to serve emergency conditions like when the elderly person faint down suddenly, or he/she asks for help due to medical complications etc.,

The reference implementation of the caring robot is shown in Fig.~

\section{Multi-robot programming at finger tips}
The Indriya system now supports NAO humanoid robots. It will soon support Turtlebot and Pepper humanoid robot. The main advantage of the system is the robot interface modules developed for each of these robots are designed in such a way that it is easy to create multiple instances (nodes) with the same script by just changing the connection parameters as shown in Listing~\ref{lst:multirobot_config}
\lstinputlisting[caption=Multi-robot Configuration File,label={lst:multirobot_config},language=XML]{assets/multirobot_config.xml}
In this way it is easy to extend the system to be used for many robots of same kind and also many different kinds of robots. 
\begin{figure}
\centering
\begin{subfigure}[t]{0.8\textwidth}
\includegraphics[width=\textwidth]{../thesis/assets/toolbox_multirobot.png}
\caption[Robot categorization]{Robot categorization}
\label{fig:robot_categorize}
\end{subfigure}

\begin{subfigure}[t]{0.8\textwidth}
\includegraphics[width=\textwidth]{../thesis/assets/toolbox_multirobot2.png}
\caption[Individual robot selection]{Individual robot selection}
\label{fig:robot_selection}
\end{subfigure}
\caption[Multi-robot support]{Multi-robot support}
\label{fig:multirobot_support}
\end{figure}
The user interface is also designed in such a way that, it is easy to choose which action to be executed in which robot. The robot actions are categorized by their types in the tool box (Fig.~\ref{fig:robot_categorize}) and with the given robot type, for each robot action blocks it is possible to choose the robot by its name (Fig.~\ref{fig:robot_selection}) as specified by the user in the configuration file.
A more appropriate scenario for human multi-robot interaction is described in Section~\ref{sec:parallel_programming}

\section{Parallel programming: Easier than ever before}
\label{sec:parallel_programming}
The Indriya platform makes it simpler to execute parallel tasks on two or more robots without any hassles. The Parallel execution block could be used for this purpose. The only constraint using this block is that one cannot execute different tasks on the same robot in parallel, which is natural. 
\subparagraph{Scenario}Let us consider a product introduction event in which the product team decided to use robots to give an introduction and demonstration of their product. Let us assume that the robots \emph{Hiro} and \emph{Taro} were used to give an introduction about \emph{Indriya} platform and its capabilities like multi-robot support, parallel execution, gesture/voice recognition support and priority based execution support etc., 
A reference implementation of this scenario is shown in Fig.~\ref{fig:complex_parallel_program}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{../thesis/assets/complex_parallel_scenario.png}
\caption[Product demo scenario: Indriya program]{Product demo scenario: Indriya program}
\label{fig:complex_parallel_program}
\end{figure}
This scenario makes use of all the capabilities of Indriya platform. Even for an intermediate programmer implementing such a scenario using say a system like ROS \cite{quigley2009ros} will be a daunting job. Parallel programming using multiple threads is tricky at times. Depending on the OS and programming language used, the constructs to build programs for parallel execution of tasks is difficult. Controlling robot in parallel is even more difficult job as the execution has to be monitored while serving other high priority human triggers. The Indriya platform gives a breezy user interface with which all these problems are effectively addressed.
\section{Summary}
In this chapter various capabilities of Indriya platform have been illustrated using example scenarios from a platform developer point of view. The video demonstration of all the scenarios could be found at the Indriya youtube channel (\url{https://www.youtube.com/playlist?list=PLm80h3-7SEzsLMZKHTOAxGW7hvnO1cKQx}) which is available as of this writing.
The Indriya platform built on latest software technologies also gives possibility to extend it easily because to its modular design. The decentralized approach makes it easy to integrate new sensors like those in smartphones, wearables etc., and new social robots as well. 